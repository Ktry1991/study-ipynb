
1.前言
------

本次实验将评估不同模型的测试精度以及过拟合问题，寻找适合的模型就像找伴侣，模型没有最好之说，只有合不合适一说。本次实验的重点在模型评估的实现过程，对分类算法本身不做深究，之后的实验中如有机会我们会尽可能慢慢讲解。本次实验相比上次实验，将会轻松愉快许多（以后尽可能一次不记太长的笔记，自己也不累，大家也好消化）。好啦，废话不多说，让我们进入正题。

2模型评估
---------

2.1　模型选择
~~~~~~~~~~~~~

学习器在训练集上的误差称为“训练误差”或者“经验误差”，在新的样本上的误差称为“泛化误差”。我们希望得到的是泛化误差小的学习器。通常，我们利用“测试集”来测试学习器对新样本的判别能力，以得到的“测试误差”来近似泛化误差。基于这种思想的学习器的评估方法，有留出法、k
折交叉验证法、留一法、自助法：

-  留出法(hold-out)：将数据集 D 划分为训练集 S 和测试集 T。通常 S 与 T
   比例为 2/3 ~ 4/5。

-  k 折交叉验证（k-fold cross validation）：将 D 划分 k
   个大小相似的子集（每份子集尽可能保持数据分布的一致性：子集中不同类别的样本数量比例与
   D 基本一致），其中一份作为测试集，剩下 k-1 份为训练集 T，操作 k 次。
   例如 D 划分为 D1，D2，... ，D10，第一次使用 D1 作为训练集，第二次使用
   D2，第三次使用 D3， ... ， 第十次使用 D10 作为测试集。最后计算 k
   次测试误差的平均值近似泛化误差。

-  留一法（Leave-One-out）：k 折交叉验证法的特例，即每次测试集 T
   只留一个数据，剩下的作为训练集 S

-  自助法（bootstrapping）：每次从数据集 D
   中有放回地采一个样本，并将这个样本放入训练集 S 中，重复 m
   次。则训练集中有 m 个训练样本，将未在训练集中的样本放入测试集 T。

留出法和 k
折交叉验证法需要划分一部分样本作为测试集，就引入由于训练样本规模不同而产生的偏差。留一法改善了这一问题，但计算复杂度高。自助法也改善了这一个问题，但改变了数据集分布，同样会引入偏差，该方法适合数据集较小的情况。所以，留出法和
k 折交叉验证法是最常用的。这里选择 k 折交叉验证法进行模型评估。

Python sklearn.model\_selection 提供了Stratified k-fold。参考 Stratified
k-fold

我推荐使用 sklearn cross\_val\_score。这个函数输入我们选择的算法、数据集
D，k
的值，输出训练精度（误差是错误率，精度是正确率）。对于分类问题，默认采用stratified
k-fold方法。参考 sklearn cross\_val\_score

下面我们用 10 折交叉验证法（k=10）对两种常用的集成学习算法 AdaBoost 以及
Random Forest 进行评估。最后我们看到 Random Forest 比 Adaboost
效果更好。

.. code:: python

    import pandas as pd
    import numpy as np
    import matplotlib as plt
    %matplotlib inline 
    from sklearn.ensemble import AdaBoostClassifier
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.model_selection import cross_val_score
    
    data = pd.read_csv('data/data.csv')
    data.head(5)




.. raw:: html

    <div>
    <style>
        .dataframe thead tr:only-child th {
            text-align: right;
        }
    
        .dataframe thead th {
            text-align: left;
        }
    
        .dataframe tbody tr th {
            vertical-align: top;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>Unnamed: 0</th>
          <th>Survived</th>
          <th>Sex</th>
          <th>Age</th>
          <th>SibSp</th>
          <th>Parch</th>
          <th>Fare</th>
          <th>Pc_1</th>
          <th>Pc_2</th>
          <th>Pc_3</th>
          <th>...</th>
          <th>T_SOPP</th>
          <th>T_SOTONO2</th>
          <th>T_SOTONOQ</th>
          <th>T_SP</th>
          <th>T_STONO</th>
          <th>T_STONO2</th>
          <th>T_SWPP</th>
          <th>T_WC</th>
          <th>T_WEP</th>
          <th>T_X</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>0</th>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>22.0</td>
          <td>1</td>
          <td>0</td>
          <td>1.981001</td>
          <td>0</td>
          <td>0</td>
          <td>1</td>
          <td>...</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
        </tr>
        <tr>
          <th>1</th>
          <td>1</td>
          <td>1</td>
          <td>1</td>
          <td>38.0</td>
          <td>1</td>
          <td>0</td>
          <td>4.266662</td>
          <td>1</td>
          <td>0</td>
          <td>0</td>
          <td>...</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
        </tr>
        <tr>
          <th>2</th>
          <td>2</td>
          <td>1</td>
          <td>1</td>
          <td>26.0</td>
          <td>0</td>
          <td>0</td>
          <td>2.070022</td>
          <td>0</td>
          <td>0</td>
          <td>1</td>
          <td>...</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>1</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
        </tr>
        <tr>
          <th>3</th>
          <td>3</td>
          <td>1</td>
          <td>1</td>
          <td>35.0</td>
          <td>1</td>
          <td>0</td>
          <td>3.972177</td>
          <td>1</td>
          <td>0</td>
          <td>0</td>
          <td>...</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>1</td>
        </tr>
        <tr>
          <th>4</th>
          <td>4</td>
          <td>0</td>
          <td>0</td>
          <td>35.0</td>
          <td>0</td>
          <td>0</td>
          <td>2.085672</td>
          <td>0</td>
          <td>0</td>
          <td>1</td>
          <td>...</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>1</td>
        </tr>
      </tbody>
    </table>
    <p>5 rows × 52 columns</p>
    </div>



.. code:: python

    y = data['Survived']
    X = data.drop(['Survived'],axis=1).values
    
    classifiers = [AdaBoostClassifier(random_state=2),RandomForestClassifier(random_state=2)]
    for clf in classifiers:
        score = cross_val_score(clf, X, y, cv=10, scoring='accuracy')
        print(np.mean(score))


.. parsed-literal::

    0.735333673817
    0.804763647713


2.2 性能度量
~~~~~~~~~~~~

过拟合是学习器性能过好，把样本的一些特性当做了数据的一般性质，从而导致训练误差低但泛化误差高。学习曲线是判断过拟合的一种方式，同时可以判断学习器的表现。学习曲线包括训练误差（或精度）随样例数目的变化曲线与测试误差（或精度）随样例数目的变化曲线。

下面我将以训练样例数目为横坐标，训练精度和测试精度为纵坐标绘制学习曲线，并分析
Random Forest 算法的性能。大家可以参考这篇博客进行深入学习 学习曲线

.. code:: python

    from sklearn.model_selection import learning_curve
    import matplotlib.pyplot as plt
    
    
    def plot_learning_curve(estimator, title, X, y, cv=10,
                            train_sizes=np.linspace(.1, 1.0, 5)):#定义函数 plot_learning_curve 绘制学习曲线。
        #train_sizes 初始化为 array([ 0.1  ,  0.325,  0.55 ,  0.775,  1.   ]),cv 初始化为 10，以后调用函数时不再输入这两个变量
        plt.figure()
        plt.title(title)#设置图的 title
        plt.xlabel('Training examples')#横坐标
        plt.ylabel('Score')#纵坐标
        train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv,
                                                                train_sizes=train_sizes)
        #使用 10 折交叉验证法，对 train_sizes*m（m为总的样例数目） 个的数据进行训练，返回训练精度 train_scores,测试精度 test_scores 
        train_scores_mean = np.mean(train_scores, axis=1)#计算平均值
        train_scores_std = np.std(train_scores, axis=1)#计算标准差
        test_scores_mean = np.mean(test_scores, axis=1)
        test_scores_std = np.std(test_scores, axis=1)
        plt.grid()#设置背景的网格
    
        plt.fill_between(train_sizes, train_scores_mean - train_scores_std,
                         train_scores_mean + train_scores_std,
                         alpha=0.1, color='g')#设置颜色
        plt.fill_between(train_sizes, test_scores_mean - test_scores_std,
                         test_scores_mean + test_scores_std,
                         alpha=0.1, color='r')
        plt.plot(train_sizes, train_scores_mean, 'o-', color='g',
                 label='traning score')#绘制训练精度曲线
        plt.plot(train_sizes, test_scores_mean, 'o-', color='r',
                 label='testing score')#绘制测试精度曲线
        plt.legend(loc='best')
        return plt
    
    g = plot_learning_curve(RandomForestClassifier(), 'RFC', X, y)#调用函数plot_learning_curve 绘制随机森林学习其学习曲线



.. image:: output_5_0.png


.. code:: python

    g = plot_learning_curve(AdaBoostClassifier(), 'AC', X, y)



.. image:: output_6_0.png


Random Forest 的学习曲线我们得到了，训练误差始终接近
0，而测试误差始终偏高，说明存在过拟合的问题。这个问题的产生是因为 Random
Forest
算法使用决策树作为基学习器，而决策树的一些特性将造成较严重的过拟合。这个问题的具体原因以及解决方法将在以后讨论。

３ 实验总结
-----------

本实验我们使用交叉验证法以及学习曲线对模型选择和性能评估进行了实例讲解，并练习使用
sklearn 机器学习工具。之后我们将继续学习如何真的随机森林分类器调参。

